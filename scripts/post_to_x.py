#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
X (Twitter) ã¸ã®è‡ªå‹•æŠ•ç¨¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

- data/products.json ã‚’èª­ã¿è¾¼ã¿
- å€¤ä¸‹ãŒã‚Šç‡ãŒæœ€å¤§ã®ã€Œãƒ™ã‚¹ãƒˆãƒ‡ã‚£ãƒ¼ãƒ«ã€å•†å“ã‚’ 1 ä»¶é¸å®š
- å•†å“å / å€¤ä¸‹ãŒã‚Šé¡ / å€¤ä¸‹ãŒã‚Šç‡ / ã‚µã‚¤ãƒˆURL / ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚° ã‚’å«ã‚€æŠ•ç¨¿æ–‡ã‚’ç”Ÿæˆ
- tweepy ã‚’ä½¿ã£ã¦ X API ã«æŠ•ç¨¿

äº‹å‰æº–å‚™:
- requirements.txt ã« tweepy ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨
- ç’°å¢ƒå¤‰æ•°ã«ä»¥ä¸‹ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨
  - VERCEL_URL
  - X_API_KEY
  - X_API_SECRET
  - X_ACCESS_TOKEN
  - X_ACCESS_SECRET
"""

import json
import logging
import os
import re
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

import tweepy

BASE_DIR = Path(__file__).resolve().parents[1]
PRODUCTS_PATH = BASE_DIR / "data" / "products.json"
POSTED_LOG_PATH = BASE_DIR / "src" / "data" / "posted_log.json"


logging.basicConfig(
  level=logging.INFO,
  format="[%(asctime)s] %(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)


def load_products() -> List[Dict[str, Any]]:
  """products.json ã‚’èª­ã¿è¾¼ã‚€"""
  if not PRODUCTS_PATH.exists():
    raise FileNotFoundError(f"products.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {PRODUCTS_PATH}")

  with PRODUCTS_PATH.open("r", encoding="utf-8") as f:
    return json.load(f)


def load_posted_log() -> List[Dict[str, Any]]:
  """éå»ã®æŠ•ç¨¿ãƒ­ã‚°ï¼ˆposted_log.jsonï¼‰ã‚’èª­ã¿è¾¼ã‚€"""
  if not POSTED_LOG_PATH.exists():
    return []

  try:
    with POSTED_LOG_PATH.open("r", encoding="utf-8") as f:
      data = json.load(f)
      if isinstance(data, list):
        return data
      return []
  except Exception as e:
    logger.warning("posted_log.json ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", e)
    return []


def save_posted_log(entries: List[Dict[str, Any]]) -> None:
  """æŠ•ç¨¿ãƒ­ã‚°ã‚’ posted_log.json ã«æ›¸ãè¾¼ã‚€"""
  POSTED_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
  with POSTED_LOG_PATH.open("w", encoding="utf-8") as f:
    json.dump(entries, f, ensure_ascii=False, indent=2)


def extract_asin(affiliate_url: str) -> Optional[str]:
  """URL ã‹ã‚‰ ASIN ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆ/dp/ ã¾ãŸã¯ /gp/product/ï¼‰"""
  if not affiliate_url:
    return None
  pattern = re.compile(r"/dp/([A-Z0-9]{10})|/gp/product/([A-Z0-9]{10})")
  match = pattern.search(affiliate_url)
  if not match:
    return None
  return match.group(1) or match.group(2)


def calc_discount_percent(product: Dict[str, Any]) -> Optional[float]:
  """å•†å“ã”ã¨ã®å€¤ä¸‹ãŒã‚Šç‡ï¼ˆ%ï¼‰ã‚’è¨ˆç®—ã™ã‚‹ã€‚å€¤ä¸‹ãŒã‚ŠãŒãªã„å ´åˆã¯ None ã‚’è¿”ã™ã€‚"""
  current_price = product.get("currentPrice")
  history = product.get("priceHistory") or []

  if current_price is None or not isinstance(history, list) or len(history) < 2:
    return None

  try:
    prev_price = float(history[-2]["price"])
    latest_price = float(current_price)
  except (KeyError, TypeError, ValueError):
    return None

  if prev_price <= 0:
    return None

  if latest_price >= prev_price:
    # å€¤ä¸‹ãŒã‚Šã—ã¦ã„ãªã„
    return None

  discount_percent = (prev_price - latest_price) / prev_price * 100.0
  return discount_percent


def find_best_deal(products: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
  """
  å€¤ä¸‹ãŒã‚Šç‡ï¼ˆpercentChangeï¼‰ãŒæœ€ã‚‚é«˜ã„å•†å“ã‚’ 1 ä»¶è¿”ã™ã€‚
  - å€¤ä¸‹ãŒã‚Šç‡ <= 0 ã®å•†å“ã¯é™¤å¤–
  - ASIN ãŒå–ã‚Œãªã„å•†å“ã‚‚é™¤å¤–
  """
  best_product: Optional[Dict[str, Any]] = None
  best_percent: float = 0.0

  for product in products:
    affiliate_url = product.get("affiliateUrl") or ""
    asin = product.get("asin") or extract_asin(affiliate_url)
    if not asin:
      continue

    percent = calc_discount_percent(product)
    if percent is None:
      continue

    if percent > best_percent:
      best_percent = percent
      best_product = product

  if best_product is None or best_percent <= 0:
    return None

  # è¦‹ã¤ã‹ã£ãŸå•†å“ã«è¨ˆç®—æ¸ˆã¿ã® percentChange ã‚’ä»˜ä¸ã—ã¦è¿”ã™
  best_product = dict(best_product)  # ã‚³ãƒ”ãƒ¼ã—ã¦æ‹¡å¼µ
  best_product["__percentChange"] = best_percent
  return best_product


def build_site_url(asin: str) -> str:
  """
  ã‚µã‚¤ãƒˆã® URL ã‚’ç”Ÿæˆã™ã‚‹ã€‚
  - VERCEL_URL ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨
  - å½¢å¼: https://{VERCEL_URL}/products/{asin}
  """
  vercel_url = os.getenv("VERCEL_URL")
  if not vercel_url:
    raise RuntimeError("ç’°å¢ƒå¤‰æ•° VERCEL_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

  # VERCEL_URL ã«ã‚¹ã‚­ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ãªã„æƒ³å®šï¼ˆä¾‹: example.vercel.appï¼‰
  base = vercel_url.strip().rstrip("/")
  if not base.startswith("http://") and not base.startswith("https://"):
    base = f"https://{base}"

  return f"{base}/products/{asin}"


def build_tweet_text(product: Dict[str, Any]) -> str:
  """
  å•†å“æƒ…å ±ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚
  - å•†å“å
  - å€¤ä¸‹ãŒã‚Šé¡
  - å€¤ä¸‹ãŒã‚Šç‡
  - ã‚µã‚¤ãƒˆURL
  - ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
  """
  name = str(product.get("name", "ä¸æ˜ãªå•†å“"))
  affiliate_url = product.get("affiliateUrl") or ""
  asin = product.get("asin") or extract_asin(affiliate_url)
  if not asin:
    raise RuntimeError("ASIN ã‚’å–å¾—ã§ããªã„ãŸã‚ã€ãƒ„ã‚¤ãƒ¼ãƒˆç”¨URLã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚")

  history = product.get("priceHistory") or []
  current_price = float(product.get("currentPrice", 0))
  prev_price = float(history[-2]["price"]) if len(history) >= 2 else current_price

  diff = prev_price - current_price
  percent = float(product.get("__percentChange", 0.0))

  url = build_site_url(asin)

  # å•†å“åãŒé•·ã™ãã‚‹å ´åˆã¯ãƒˆãƒªãƒ 
  max_name_length = 60
  if len(name) > max_name_length:
    name = name[: max_name_length - 1] + "â€¦"

  tweet = (
    f"ğŸ“‰æœ¬æ—¥ã®ãƒ™ã‚¹ãƒˆãƒ‡ã‚£ãƒ¼ãƒ«\n"
    f"{name}\n"
    f"ä¾¡æ ¼: Â¥{int(current_price):,}ï¼ˆ-{int(diff):,}å†† / -{percent:.1f}%ï¼‰\n"
    f"{url}\n"
    f"#Amazon #TRENDIX #ã‚»ãƒ¼ãƒ«"
  )

  return tweet


def get_twitter_client() -> tweepy.API:
  """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€tweepy ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
  api_key = os.getenv("X_API_KEY")
  api_secret = os.getenv("X_API_SECRET")
  access_token = os.getenv("X_ACCESS_TOKEN")
  access_secret = os.getenv("X_ACCESS_SECRET")

  if not all([api_key, api_secret, access_token, access_secret]):
    raise RuntimeError(
      "X API ã®èªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚X_API_KEY, X_API_SECRET, X_ACCESS_TOKEN, X_ACCESS_SECRET ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    )

  auth = tweepy.OAuth1UserHandler(
    api_key,
    api_secret,
    access_token,
    access_secret,
  )
  api = tweepy.API(auth)
  return api


def is_recently_posted(asin: str, log_entries: List[Dict[str, Any]], hours: int = 24) -> bool:
  """æŒ‡å®šã—ãŸ ASIN ãŒç›´è¿‘ hours æ™‚é–“ä»¥å†…ã«æŠ•ç¨¿ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹"""
  now = datetime.now(timezone.utc)
  cutoff = now - timedelta(hours=hours)

  for entry in log_entries:
    if entry.get("asin") != asin:
      continue
    ts_str = entry.get("timestamp")
    if not ts_str:
      continue
    try:
      ts = datetime.fromisoformat(ts_str)
    except ValueError:
      continue
    if ts.tzinfo is None:
      ts = ts.replace(tzinfo=timezone.utc)
    if ts >= cutoff:
      return True
  return False


def append_post_log(asin: str, log_entries: List[Dict[str, Any]], keep_hours: int = 48) -> List[Dict[str, Any]]:
  """
  æ–°ã—ã„æŠ•ç¨¿ã‚’ãƒ­ã‚°ã«è¿½åŠ ã—ã€å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã€‚
  - keep_hours æ™‚é–“ã‚ˆã‚Šå¤ã„ã‚‚ã®ã¯å‰Šé™¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ48æ™‚é–“ï¼‰
  """
  now = datetime.now(timezone.utc)
  cutoff = now - timedelta(hours=keep_hours)

  cleaned: List[Dict[str, Any]] = []
  for entry in log_entries:
    ts_str = entry.get("timestamp")
    if not ts_str:
      continue
    try:
      ts = datetime.fromisoformat(ts_str)
    except ValueError:
      continue
    if ts.tzinfo is None:
      ts = ts.replace(tzinfo=timezone.utc)
    if ts >= cutoff:
      cleaned.append(entry)

  cleaned.append(
    {
      "asin": asin,
      "timestamp": now.isoformat(),
    }
  )
  return cleaned


def post_best_deal_to_x() -> None:
  """ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼: ãƒ™ã‚¹ãƒˆãƒ‡ã‚£ãƒ¼ãƒ«ã‚’é¸å®šã—ã€X ã«æŠ•ç¨¿ã™ã‚‹ã€‚"""
  try:
    products = load_products()
  except Exception as e:
    logger.error("å•†å“ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", e)
    return

  best_product = find_best_deal(products)
  if not best_product:
    logger.info("å€¤ä¸‹ãŒã‚Šç‡ãŒæ­£ã®ãƒ™ã‚¹ãƒˆãƒ‡ã‚£ãƒ¼ãƒ«å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    return

  affiliate_url = best_product.get("affiliateUrl") or ""
  asin = best_product.get("asin") or extract_asin(affiliate_url)
  if not asin:
    logger.error("ãƒ™ã‚¹ãƒˆãƒ‡ã‚£ãƒ¼ãƒ«å•†å“ã® ASIN ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æŠ•ç¨¿ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
    return

  # éå»24æ™‚é–“ã®æŠ•ç¨¿å±¥æ­´ã‚’ãƒã‚§ãƒƒã‚¯
  log_entries = load_posted_log()
  if is_recently_posted(asin, log_entries, hours=24):
    logger.info("ASIN %s ã¯éå»24æ™‚é–“ä»¥å†…ã«æŠ•ç¨¿æ¸ˆã¿ã®ãŸã‚ã€å†æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚", asin)
    return

  try:
    tweet_text = build_tweet_text(best_product)
  except Exception as e:
    logger.error("ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: %s", e)
    return

  try:
    api = get_twitter_client()
  except Exception as e:
    logger.error("X API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", e)
    return

  try:
    logger.info("X ã¸æŠ•ç¨¿ä¸­: %s", tweet_text.replace("\n", " / "))
    api.update_status(status=tweet_text)
    logger.info("X ã¸ã®æŠ•ç¨¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # æŠ•ç¨¿æˆåŠŸæ™‚ã«ãƒ­ã‚°ã‚’æ›´æ–°ï¼ˆéå»48æ™‚é–“åˆ†ã ã‘ä¿æŒï¼‰
    updated_log = append_post_log(asin, log_entries, keep_hours=48)
    save_posted_log(updated_log)

  except Exception as e:
    logger.error("X ã¸ã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", e)


if __name__ == "__main__":
  post_best_deal_to_x()


